<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Xingjian Gao</title>

  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Xingjian Gao</name>
              </p>
              <p>
                Hi, I am Xingjian Gao, a 5th Year Master student from the Department of Electrical Engineering and Computer Sciences (EECS) at University of California, Berkeley. I major in Computer Science and Applied Mathematics during my undergrad study at UC Berkeley. I am from Changzhou, China.
              </p>
              <p style="text-align:center">
<!--                 <a href="xgao@berkeley.edu">Email</a> &nbsp/&nbsp -->
                <a href="data/Resume.pdf">Resume</a> &nbsp/&nbsp
                <a href="data/Courses.txt">Classes</a> &nbsp/&nbsp
<!--                 <a href="https://scholar.google.com/citations?hl=en&user=hYlbtl8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
<!--                 <a href="https://github.com/xgao0613">Github</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Xingjian.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Xingjian.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                 I am currently a student researcher in Berkeley Artificial Intelligence Research Lab (BAIR) advised by Prof.<a href="https://people.eecs.berkeley.edu/~yima">Yi Ma</a>. I also work closely with Xili Dai from Prof. Heung-Yeung Shum's lab in HKUST(GZ). My research interest lies in interpretability of deep learning, sparse coding, generative models, and representation learning. I am also interested in using deep learning to understand visual perception in primates and am working with Prof.<a href="https://vcresearch.berkeley.edu/faculty/doris-tsao">Doris Tsao</a> on interpreting neural data with generative models.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <heading>Publications & Preprints (* means equal contribution)</heading>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CSC_CTRL.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
                <papertitle> Closed-Loop Transcription Via Convolutional Sparse Coding</papertitle>
              </a>
              <br>
              Xili Dai*, Ke Chen*, Shengbang Tong*, Jingyuan Zhang*, Xingjian Gao, Mingyang Li, Druv Pai, Yuexiang Zhai, Xiaojun Yuan, Heung Yeung Shum, Lionel M.Ni, Yi Ma
              <br>
              <em>Under Review</em>
              <br>
              <p>ICLR 2023 (Under Review)</p>
              <p>This paper proposes a new unsupervised method to learn a represenation and cluster for real life dataset such as CIFAR-10, CIFAR100 and Tiny-ImageNet-200.</p>
            </td>
          </tr>

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/CSC.png" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <a href="https://arxiv.org/abs/2210.12945" id="revisit">
                <papertitle>Revisiting Sparse Convolutional Model for Visual Recognition</papertitle>
              </a>
              <br>
              Xili Dai*, Mingyang Li*, Pengyuan Zhai, Shengbang Tong, Xingjian Gao, Shaolun Huang, Zhihui Zhu, Chong You, Yi Ma
              <br>
              <em>NeurIPS 2022 (Accepted)</em>
              <br>
              <p></p>
              <p>Our method uses differentiable optimization layers that are defined from convolutional sparse coding as drop-in replacements of standard convolutional layers in conventional deep neural networks. We show that such models have equally strong empirical performance on CIFAR-10, CIFAR-100 and ImageNet datasets when compared to conventional neural networks.</p>
            </td>
          </tr>

       <table class="sub-table" style="width: 200px;height: 100px;" align="center">
         <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=y35-AqSkeLIkce_C13W-97DGULFZQWj5YJB3rNARabY&cl=ffffff&w=a"></script>
      </table>
        </tbody></table>

      </td>
    </tr>
  </table>
</body>

</html>
